import os
from openai import OpenAI
from model import ChatBot
import torch
import datetime

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY")
)
MODEL = "gpt-3.5-turbo"


def log_dialogue(user_input, bot_output, corrected_text):
    # å®šä¹‰æ—¥å¿—æ–‡ä»¶çš„åç§°
    log_file = "dialogues.log"
    # è·å–å½“å‰æ—¶é—´
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    # å‡†å¤‡è¦è®°å½•çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ˜¯å¦è¢«æ ‡è®°ä¸º'0'
    status = "Unrealistic" if corrected_text.strip() == '0' else "Adjusted"
    log_entry = f"{now} - Status: {status} - User Input: {user_input} - Bot Output: {bot_output} - Corrected: {corrected_text}\n"

    # å°†ä¿¡æ¯å†™å…¥æ—¥å¿—æ–‡ä»¶
    with open(log_file, "a") as file:
        file.write(log_entry)


def get_response(inputSeq):
    if inputSeq == 'null' or inputSeq == 'invalid':
        error_message = "Hmm, I didn't quite catch that. Could you rephrase or give me a bit more detail? I'm here to help! ğŸŒŸ";
        return error_message

    modelPath = "testc.pkl"
    chatBot = ChatBot(modelPath, device=torch.device('cpu'))

    print("loading the model...")
    outputSeq = chatBot.predictByBeamSearch(inputSeq, isRandomChoose=False)
    print("outputSeq", outputSeq)
    # ä½¿ç”¨OpenAI APIçº æ­£outputSeqçš„è¯­æ³•
    corrected_outputSeq = postprocessing(inputSeq, outputSeq)
    print("Corrected output: ", corrected_outputSeq)
    return corrected_outputSeq


def postprocessing(user_input, bot_output):
    try:
        instructions = (
            "Imagine you are an assistant whose role is to support a chatbot designed for student interactions, "
            "with a focus on mental health and stress among other topics. Your task is to evaluate the conversation "
            "based on the user input"
            "and the chatbot's predicted output. You should judge the conversation's relevance and realism. "
            "If the dialogue is something that can happen in reality and makes sense within the context of a "
            "student's life,"
            "including but not limited to mental health and stress, correct any grammatical errors in the chatbot's "
            "response,"
            "adjust casing where appropriate, add necessary punctuation, and ensure the response is accurate and "
            "sounds natural."
            "If the conversation does not make sense or could not realistically occur, return '0'."
        )

        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": instructions
                },
                {
                    "role": "user",
                    "content": user_input,
                },
                {
                    "role": "assistant",
                    "content": bot_output,
                }
            ],
            temperature=0.5,
        )

        corrected_text = response.choices[0].message.content

        if corrected_text.strip() == '0':
            print("This dialogue can't happen in reality.")
            # å¦‚æœè¢«æ ‡è®°ä¸º'0'ï¼Œä¾ç„¶è®°å½•å¯¹è¯ï¼Œä½†çŠ¶æ€ä¸º"Unrealistic"
            log_dialogue(user_input, bot_output, corrected_text)
            # å¯ä»¥é€‰æ‹©è¿”å›åŸå§‹botè¾“å‡º
            return bot_output
        else:
            print("User input is related, and the bot's response has been adjusted.")
            # è®°å½•å¯¹è¯ï¼ŒçŠ¶æ€ä¸º"Adjusted"
            log_dialogue(user_input, bot_output, corrected_text)
            return corrected_text
    except Exception as e:
        print(f"An error occurred: {e}")
        # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œä¹Ÿè®°å½•è¿™æ¬¡å¯¹è¯å°è¯•
        log_dialogue(user_input, bot_output, "Error occurred")
        # åœ¨å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹æ–‡æœ¬
        return bot_output

# test
# get_response("hi,there")